{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e20a74e-5240-410f-98e4-a0d021497771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from scipy.stats import linregress\n",
    "from scipy import stats\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e397ea-f32f-42a7-9357-3ff148214d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import permutation_test\n",
    "\n",
    "def perm_test(group1, group2, n_permutations=10000):\n",
    "    observed_diff = np.mean(group1) - np.mean(group2)\n",
    "    \n",
    "    def statistic(x, y):\n",
    "        return np.mean(x) - np.mean(y)\n",
    "    \n",
    "    result = permutation_test(\n",
    "        data=(group1, group2),\n",
    "        statistic=statistic,\n",
    "        permutation_type='independent',\n",
    "        vectorized=False,  # importante: no usar vectorized\n",
    "        n_resamples=n_permutations,\n",
    "        alternative='two-sided',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    return observed_diff, result.pvalue\n",
    "\n",
    "def cliffs_delta(x, y):\n",
    "    n_x = len(x)\n",
    "    n_y = len(y)\n",
    "    all_pairs = [(xi, yi) for xi in x for yi in y]\n",
    "    n_greater = sum(1 for xi, yi in all_pairs if xi > yi)\n",
    "    n_less = sum(1 for xi, yi in all_pairs if xi < yi)\n",
    "    \n",
    "    delta = (n_greater - n_less) / (n_x * n_y)\n",
    "    return delta\n",
    "\n",
    "# Función para quitar outliers con IQR\n",
    "def remove_outliers_iqr(df, col, thres=1.5):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - thres * IQR\n",
    "    upper = Q3 + thres * IQR\n",
    "    return df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "\n",
    "def mean_directional_accuracy(y_true, y_pred):\n",
    "    \n",
    "    differences = np.array(y_pred) - np.array(y_true) \n",
    "    signs = np.sign(differences)\n",
    "    mde = np.mean(signs)\n",
    "    return mde\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    absolute_errors = np.abs(y_pred - y_true)\n",
    "    mae = np.mean(absolute_errors)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "def coef_pval(coef_array_mean_, X_, y_, y_p):\n",
    "\n",
    "    n = X_.shape[0]\n",
    "    t = coef_tval(coef_array_mean_, X_, y_, y_p)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "\n",
    "def coef_tval(coef_array_mean_, X_, y_, y_p):\n",
    "    \n",
    "    '''\n",
    "        coef_tval for OLS of statsmodels\n",
    "    '''\n",
    "    \n",
    "    a = np.array(coef_array_mean_[0][0]/ coef_se(X_, y_, y_p)[0])\n",
    "    b = np.array(coef_array_mean_[1::].flatten() / coef_se(X_, y_, y_p)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "\n",
    "def coef_se(X_, y_, y_p):\n",
    "    \n",
    "    '''\n",
    "        coef_se for OLS of statsmodels\n",
    "    '''\n",
    "    n = X_.shape[0]\n",
    "    \n",
    "    X1 = np.hstack((np.ones((n, 1)), np.matrix(X_)))\n",
    "    se_matrix = scipy.linalg.sqrtm(\n",
    "        metrics.mean_squared_error(y_, y_p) *\n",
    "        np.linalg.inv(X1.T * X1)\n",
    "    )\n",
    "    return np.diagonal(se_matrix)\n",
    "\n",
    "def directional_accuracy(predicted_values, true_values):\n",
    "\n",
    "    predicted_values = np.array(predicted_values)\n",
    "    true_values = np.array(true_values)    \n",
    "\n",
    "    difference_direction = np.sign(predicted_values - true_values)    \n",
    "    correct_direction_count = np.sum(difference_direction == 1) + np.sum(difference_direction == -1)\n",
    "    \n",
    "    directional_accuracy_score = correct_direction_count / len(predicted_values)\n",
    "    \n",
    "    return directional_accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from statsmodels.api import GLM\n",
    "from statsmodels.api import families\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import linregress\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import warnings\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436255b7-e9aa-48a4-8b17-3aad5281cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def remove_outliers_iqr(df, col, iqr_k=1.5):\n",
    "    s = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    q1 = s.quantile(0.25)\n",
    "    q3 = s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    low = q1 - iqr_k * iqr\n",
    "    high = q3 + iqr_k * iqr\n",
    "    return df.loc[(s >= low) & (s <= high)].copy()\n",
    "\n",
    "def cliffs_delta(x, y):\n",
    "    x = pd.to_numeric(pd.Series(x).dropna(), errors=\"coerce\").dropna().values\n",
    "    y = pd.to_numeric(pd.Series(y).dropna(), errors=\"coerce\").dropna().values\n",
    "    nx, ny = len(x), len(y)\n",
    "    if nx == 0 or ny == 0:\n",
    "        return np.nan\n",
    "    diffs = x[:, None] - y[None, :]\n",
    "    n_greater = np.sum(diffs > 0)\n",
    "    n_less = np.sum(diffs < 0)\n",
    "    return float((n_greater - n_less) / (nx * ny))\n",
    "\n",
    "def permutation_pvalue(x, y, n_perm=10000, seed=42):\n",
    "    \"\"\"Two-sided permutation test for mean difference\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    x = np.array(x.dropna())\n",
    "    y = np.array(y.dropna())\n",
    "    if len(x) == 0 or len(y) == 0:\n",
    "        return np.nan\n",
    "    obs_diff = np.abs(np.mean(x) - np.mean(y))\n",
    "    combined = np.concatenate([x, y])\n",
    "    nx = len(x)\n",
    "    count = 0\n",
    "    for _ in range(n_perm):\n",
    "        rng.shuffle(combined)\n",
    "        x_perm, y_perm = combined[:nx], combined[nx:]\n",
    "        diff = np.abs(np.mean(x_perm) - np.mean(y_perm))\n",
    "        if diff >= obs_diff:\n",
    "            count += 1\n",
    "    return count / n_perm\n",
    "\n",
    "def chunk_list(lst, n):\n",
    "    \"\"\"Split list into chunks of size n.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "def plot_gap_by_diagnosis_clean_wrap(\n",
    "    df,\n",
    "    gap_col,\n",
    "    diagnosis_list,\n",
    "    thresholds=(0.1, 0.5, 1.0, 1.5),\n",
    "    per_line=3,\n",
    "    title_fontsize=8,\n",
    "    n_perm=10000\n",
    "):\n",
    "    # Build original data by group\n",
    "    group_data_orig = {}\n",
    "    for diag in diagnosis_list:\n",
    "        sub = df[df[\"clinical_diagnosis\"] == diag][[gap_col]].copy()\n",
    "        sub[\"Origen\"] = diag\n",
    "        group_data_orig[diag] = sub\n",
    "\n",
    "    # Unique pairs without repetition\n",
    "    all_pairs = [(diagnosis_list[i], diagnosis_list[j])\n",
    "                 for i in range(len(diagnosis_list))\n",
    "                 for j in range(i+1, len(diagnosis_list))]\n",
    "\n",
    "    cn_pairs = [(a, b) for (a, b) in all_pairs if a == \"CN\"]\n",
    "    other_pairs = [p for p in all_pairs if p not in cn_pairs]\n",
    "\n",
    "    results_table = []\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(7.0, 8.0), sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for ax, iqr_k in zip(axes, thresholds):\n",
    "        group_data_clean = {\n",
    "            diag: remove_outliers_iqr(group_data_orig[diag], gap_col, iqr_k)\n",
    "            for diag in diagnosis_list\n",
    "        }\n",
    "\n",
    "        cn_lines = []\n",
    "        for a, b in cn_pairs:\n",
    "            x = group_data_clean[a][gap_col]\n",
    "            y = group_data_clean[b][gap_col]\n",
    "            dval = cliffs_delta(x, y)\n",
    "            pval = permutation_pvalue(x, y, n_perm=n_perm)\n",
    "            cn_lines.append(f\"{a}-{b}: {dval:.3f}\")\n",
    "            results_table.append([iqr_k, a, b, dval, pval])\n",
    "\n",
    "        other_lines = []\n",
    "        for a, b in other_pairs:\n",
    "            x = group_data_clean[a][gap_col]\n",
    "            y = group_data_clean[b][gap_col]\n",
    "            dval = cliffs_delta(x, y)\n",
    "            pval = permutation_pvalue(x, y, n_perm=n_perm)\n",
    "            other_lines.append(f\"{a}-{b}: {dval:.3f}\")\n",
    "            results_table.append([iqr_k, a, b, dval, pval])\n",
    "\n",
    "        cn_wrapped = [\" | \".join(chunk) for chunk in chunk_list(cn_lines, per_line)]\n",
    "        other_wrapped = [\" | \".join(chunk) for chunk in chunk_list(other_lines, per_line)]\n",
    "\n",
    "        title_parts = [f\"IQR={iqr_k}\"] + cn_wrapped + other_wrapped\n",
    "        ax.set_title(\"\\n\".join(title_parts), fontsize=title_fontsize)\n",
    "\n",
    "        combined = pd.concat([group_data_clean[d] for d in diagnosis_list], ignore_index=True)\n",
    "        sns.boxplot(data=combined, x=\"Origen\", y=gap_col, order=diagnosis_list, ax=ax)\n",
    "        ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(gap_col)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    results_df = pd.DataFrame(results_table, columns=[\"IQR_k\", \"Group1\", \"Group2\", \"CliffsDelta\", \"p_value\"])\n",
    "    return fig, axes, results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12abd874-4760-474a-b575-9ad1d7da47fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from scipy.stats import linregress\n",
    "import shap\n",
    "\n",
    "\n",
    "def run_nested_hgb(\n",
    "    df_data,\n",
    "    selected_hgb,\n",
    "    n_splits_outer = 10,\n",
    "    n_splits_inner = 5,\n",
    "    random_state = 42,\n",
    "    scaler_range=(0.05, 0.95),\n",
    "    param_grid=None,\n",
    "    n_perm_repeats: int = 30,\n",
    "    shap_check_additivity: bool = False,\n",
    "    verbose: int = 2\n",
    "):\n",
    "\n",
    "\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            \"model__max_iter\": [300, 400, 500, 600],\n",
    "            \"model__max_depth\": [3, 5, 7],\n",
    "            \"model__learning_rate\": [0.01, 0.05, 0.1],\n",
    "        }\n",
    "\n",
    "    if isinstance(selected_hgb, str):\n",
    "        selected_hgb = [selected_hgb]\n",
    "    selected_hgb = list(selected_hgb)\n",
    "\n",
    "    y = df_data[\"demo_age\"]\n",
    "    X_selected = df_data[selected_hgb]\n",
    "\n",
    "    kf_outer = KFold(n_splits=n_splits_outer, shuffle=True, random_state=random_state)\n",
    "\n",
    "    r2_scores = []\n",
    "    y_true_all, y_pred_all = [], []\n",
    "\n",
    "    results_labels_df = pd.DataFrame(columns=[\n",
    "        'y_labels', 'y_pred', 'y_pred_M1', 'y_pred_M2', 'y_pred_M3',\n",
    "        'GAP', 'GAP_corrected_M1', 'GAP_corrected_M2', 'GAP_corrected_M3', 'ID'\n",
    "    ])\n",
    "\n",
    "    shap_values_sum = pd.Series(0.0, index=X_selected.columns)\n",
    "    perm_values_sum = pd.Series(0.0, index=X_selected.columns)\n",
    "\n",
    "    best_params_by_fold = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf_outer.split(X_selected), start=1):\n",
    "        print(f\" Fold {fold} (Nested CV)\")\n",
    "\n",
    "        X_train, X_test = X_selected.iloc[train_idx], X_selected.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            (\"scaler\", MinMaxScaler(feature_range=scaler_range)),\n",
    "            (\"model\", HistGradientBoostingRegressor(random_state=random_state))\n",
    "        ])\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=param_grid,\n",
    "            scoring=\"r2\",\n",
    "            cv=n_splits_inner,\n",
    "            n_jobs=-1,\n",
    "            verbose=verbose\n",
    "        )\n",
    "\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params_by_fold.append(grid_search.best_params_)\n",
    "\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "        print(f\" R² fold {fold}: {r2:.4f} (best params: {grid_search.best_params_})\")\n",
    "\n",
    "        y_true_all.extend(y_test.tolist())\n",
    "        y_pred_all.extend(y_pred.tolist())\n",
    "\n",
    "        gap_test = y_pred - y_test\n",
    "        gap_train_all = best_model.predict(X_train) - y_train\n",
    "\n",
    "        train_ids = X_train.index\n",
    "        diag_train = df_data.loc[train_ids, 'clinical_diagnosis']\n",
    "        cn_mask = (diag_train == 'CN').values  \n",
    "\n",
    "        if cn_mask.sum() >= 2:\n",
    "            slope, intercept, _, _, _ = linregress(y_train.values[cn_mask], gap_train_all.values[cn_mask])\n",
    "        else:\n",
    "            slope, intercept = 0.0, 0.0 \n",
    "\n",
    "        corrected_gap_M1 = gap_test - (slope * y_test + intercept)\n",
    "        y_pred_M1 = y_test + corrected_gap_M1\n",
    "\n",
    "        y_train_pred = best_model.predict(X_train)\n",
    "        if cn_mask.sum() >= 2:\n",
    "            slope_pred, intercept_pred, _, _, _ = linregress(y_train.values[cn_mask], y_train_pred[cn_mask])\n",
    "            if slope_pred == 0:\n",
    "                slope_pred = 1.0\n",
    "        else:\n",
    "            slope_pred, intercept_pred = 1.0, 0.0\n",
    "\n",
    "        y_pred_M2 = (y_pred - intercept_pred) / slope_pred\n",
    "        corrected_gap_M2 = y_pred_M2 - y_test\n",
    "\n",
    "        y_pred_M3 = (y_pred - intercept_pred) / slope_pred\n",
    "        corrected_gap_M3 = y_pred_M3 - y_test\n",
    "\n",
    "        explainer = shap.Explainer(best_model.named_steps['model'], X_train)\n",
    "        shap_values = explainer(X_test, check_additivity=shap_check_additivity)\n",
    "        shap_values_mean = np.abs(shap_values.values).mean(axis=0)\n",
    "        shap_values_sum += pd.Series(shap_values_mean, index=X_selected.columns)\n",
    "\n",
    "        perm_importance = permutation_importance(\n",
    "            best_model, X_test, y_test,\n",
    "            n_repeats=n_perm_repeats,\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        perm_values_sum += pd.Series(perm_importance.importances_mean, index=X_selected.columns)\n",
    "\n",
    "        result = np.column_stack((\n",
    "            y_test, y_pred, y_pred_M1, y_pred_M2, y_pred_M3,\n",
    "            gap_test, corrected_gap_M1, corrected_gap_M2, corrected_gap_M3\n",
    "        ))\n",
    "        temp_df = pd.DataFrame(result, columns=[\n",
    "            'y_labels', 'y_pred', 'y_pred_M1', 'y_pred_M2', 'y_pred_M3',\n",
    "            'GAP', 'GAP_corrected_M1', 'GAP_corrected_M2', 'GAP_corrected_M3'\n",
    "        ])\n",
    "        temp_df['ID'] = X_test.index\n",
    "\n",
    "        results_labels_df = pd.concat([results_labels_df, temp_df], ignore_index=True)\n",
    "\n",
    "    r2_mean = float(np.mean(r2_scores))\n",
    "    r2_std = float(np.std(r2_scores))\n",
    "    r2_global = float(r2_score(y_true_all, y_pred_all))\n",
    "\n",
    "    print(\"\\n R² promedio:\", r2_mean, r2_std)\n",
    "    print(\" R² global:\", r2_global)\n",
    "\n",
    "    shap_importance_avg = (shap_values_sum / kf_outer.get_n_splits()).sort_values(ascending=False)\n",
    "    perm_importance_avg = (perm_values_sum / kf_outer.get_n_splits()).sort_values(ascending=False)\n",
    "\n",
    "    results_labels_df = results_labels_df.set_index('ID').sort_index()\n",
    "    df_final = pd.concat(\n",
    "        [df_data[['demo_age', 'clinical_diagnosis'] + selected_hgb], results_labels_df],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    out = {\n",
    "        \"selected_hgb\": selected_hgb,\n",
    "        \"df_final\": df_final,\n",
    "        \"results_labels_df\": results_labels_df,\n",
    "        \"r2_scores\": r2_scores,\n",
    "        \"r2_mean\": r2_mean,\n",
    "        \"r2_std\": r2_std,\n",
    "        \"r2_global\": r2_global,\n",
    "        \"y_true_all\": y_true_all,\n",
    "        \"y_pred_all\": y_pred_all,\n",
    "        \"best_params_by_fold\": best_params_by_fold,\n",
    "        \"shap_importance_avg\": shap_importance_avg,\n",
    "        \"perm_importance_avg\": perm_importance_avg,\n",
    "    }\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d265350e-be3f-4948-842a-98b4cf799693",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e9dd3-46db-4bf1-b4b8-6039d34cb7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_excel('../Data/augmented_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97276bab-0352-45e9-ac3e-276b77378b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_hgb = ['concreteness',\n",
    "       'granularity_extraction', 'psycholinguistic_objective',\n",
    "       'pitch_analysis', 'sentiment_analysis', 'talking_intervals',\n",
    "       'verbosity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9191525-f7b7-4a8f-b1c2-845864759502",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3becb821-fc41-44f3-a380-eacd542f5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_nested_hgb(df_data, selected_hgb, n_splits_outer = 10, n_splits_inner = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2431c0dc-333e-41e1-838b-8d132ac269c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
